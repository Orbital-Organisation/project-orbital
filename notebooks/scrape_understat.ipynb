{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jsonb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjsonb\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'jsonb'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import jsonb\n",
    "import re\n",
    "import pandas as pd\n",
    "from itables import show\n",
    "import json\n",
    "\n",
    "\n",
    "def get_parsed_html(url: str):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        return soup\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching the page: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_players_data(soup):\n",
    "    try:\n",
    "        scripts = soup.find_all(\"script\")\n",
    "        for script in scripts:\n",
    "            if \"var playersData\" in script.text:\n",
    "                match = re.search(\n",
    "                    r\"var playersData\\s*=\\s*JSON\\.parse\\((.*?)\\);\",\n",
    "                    script.text,\n",
    "                    re.DOTALL,\n",
    "                )\n",
    "                if match:\n",
    "                    json_data = match.group(1)\n",
    "                    clean_data = (\n",
    "                        json_data.strip(\"'\").encode(\"utf-8\").decode(\"unicode_escape\")\n",
    "                    )\n",
    "                    players_data = json.loads(clean_data)\n",
    "                    return players_data\n",
    "        print(\"playersData not found in scripts.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting playersData: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "url = \"https://understat.com/league/EPL/2024\"\n",
    "parsed_html = get_parsed_html(url)\n",
    "\n",
    "if parsed_html:\n",
    "    players_data = extract_players_data(parsed_html)\n",
    "    if players_data:\n",
    "        print(\"Extracted playersData:\")\n",
    "        print(players_data)\n",
    "    else:\n",
    "        print(\"No playersData found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import jsonb\n",
    "import re\n",
    "import pandas as pd\n",
    "from itables import show\n",
    "\n",
    "\n",
    "def get_parsed_html(url: str):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        return soup\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching the page: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_players_data(soup):\n",
    "    try:\n",
    "        scripts = soup.find_all(\"script\")\n",
    "        for script in scripts:\n",
    "            if \"var playersData\" in script.text:\n",
    "                match = re.search(\n",
    "                    r\"var playersData\\s*=\\s*JSON\\.parse\\((.*?)\\);\",\n",
    "                    script.text,\n",
    "                    re.DOTALL,\n",
    "                )\n",
    "                if match:\n",
    "                    json_data = match.group(1)\n",
    "                    clean_data = (\n",
    "                        json_data.strip(\"'\").encode(\"utf-8\").decode(\"unicode_escape\")\n",
    "                    )\n",
    "                    players_data = json.loads(clean_data)\n",
    "                    return players_data\n",
    "        print(\"playersData not found in scripts.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting playersData: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "url = \"https://understat.com/league/EPL/2024\"\n",
    "parsed_html = get_parsed_html(url)\n",
    "\n",
    "if parsed_html:\n",
    "    players_data = extract_players_data(parsed_html)\n",
    "    if players_data:\n",
    "        print(\"Extracted playersData:\")\n",
    "        print(players_data)\n",
    "    else:\n",
    "        print(\"No playersData found.\")\n",
    "\n",
    "understat_leagues = [\"EPL\", \"La_liga\", \"Bundesliga\", \"Serie_A\", \"Ligue_1\", \"RFPL\"]\n",
    "\n",
    "\n",
    "def get_understat_url(league_name, year=\"2024\"):\n",
    "    \"\"\"\n",
    "    Constructs the Understat league URL based on the league name.\n",
    "\n",
    "    Args:\n",
    "        league_name (str): The name of the league (e.g., \"EPL\", \"La_liga\").\n",
    "        year (str): The season year (default is \"2024\").\n",
    "\n",
    "    Returns:\n",
    "        str: The constructed URL for the given league and year.\n",
    "    \"\"\"\n",
    "    base_url = \"https://understat.com/league/\"\n",
    "    if league_name not in understat_leagues:\n",
    "        return f\"League name '{league_name}' is not valid. Available options: {', '.join(understat_leagues)}\"\n",
    "    return f\"{base_url}{league_name}/{year}\"\n",
    "\n",
    "\n",
    "df = pd.DataFrame(players_data)\n",
    "\n",
    "numerical_columns = [\n",
    "    \"games\",\n",
    "    \"time\",\n",
    "    \"goals\",\n",
    "    \"xG\",\n",
    "    \"assists\",\n",
    "    \"xA\",\n",
    "    \"shots\",\n",
    "    \"key_passes\",\n",
    "    \"yellow_cards\",\n",
    "    \"red_cards\",\n",
    "    \"npg\",\n",
    "    \"npxG\",\n",
    "    \"xGChain\",\n",
    "    \"xGBuildup\",\n",
    "]\n",
    "df[numerical_columns] = df[numerical_columns].apply(pd.to_numeric)\n",
    "\n",
    "features = [\"goals\", \"shots\", \"xG\", \"xA\", \"npg\", \"npxG\", \"xGChain\", \"xGBuildup\"]\n",
    "X = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "df[\"Cluster\"] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "cluster_means = df.groupby(\"Cluster\")[features].mean()\n",
    "print(\"Cluster Means:\\n\", cluster_means)\n",
    "\n",
    "\n",
    "def assign_cluster_labels(cluster_means):\n",
    "    labels = {}\n",
    "    sorted_clusters = cluster_means[[\"goals\", \"xA\", \"xGBuildup\"]].idxmax()\n",
    "    labels[sorted_clusters[\"goals\"]] = \"High Scorers\"\n",
    "    labels[sorted_clusters[\"xA\"]] = \"Playmakers\"\n",
    "    labels[sorted_clusters[\"xGBuildup\"]] = \"Defenders\"\n",
    "    for cluster in cluster_means.index:\n",
    "        if cluster not in labels:\n",
    "            labels[cluster] = \"All-Rounders\"\n",
    "    return labels\n",
    "\n",
    "\n",
    "cluster_labels = assign_cluster_labels(cluster_means)\n",
    "\n",
    "df[\"Cluster Label\"] = df[\"Cluster\"].map(cluster_labels)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "df[\"PCA1\"] = X_pca[:, 0]\n",
    "df[\"PCA2\"] = X_pca[:, 1]\n",
    "\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x=\"PCA1\",\n",
    "    y=\"PCA2\",\n",
    "    color=\"Cluster Label\",\n",
    "    title=\"Enhanced Interactive Player Clusters\",\n",
    "    hover_data=[\n",
    "        \"player_name\",\n",
    "        \"team_title\",\n",
    "        \"goals\",\n",
    "        \"assists\",\n",
    "        \"xG\",\n",
    "        \"xA\",\n",
    "        \"shots\",\n",
    "        \"Cluster Label\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    legend_title=\"Cluster Description\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
    "    xaxis_title=\"PCA Component 1\",\n",
    "    yaxis_title=\"PCA Component 2\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "def find_similar_players(player_name, df, X_scaled, top_n=5):\n",
    "    if player_name not in df[\"player_name\"].values:\n",
    "        return f\"Player {player_name} not found in the dataset.\"\n",
    "\n",
    "    player_idx = df[df[\"player_name\"] == player_name].index[0]\n",
    "\n",
    "    distances = cdist([X_scaled[player_idx]], X_scaled, metric=\"euclidean\")[0]\n",
    "    print(distances)\n",
    "\n",
    "    similar_idx = distances.argsort()[1 : top_n + 1]\n",
    "\n",
    "    similar_players = df.iloc[similar_idx][[\"player_name\", \"team_title\"]]\n",
    "    similar_players[\"Similarity Score\"] = distances[similar_idx]\n",
    "    return similar_players\n",
    "\n",
    "\n",
    "target_player = \"Erling Haaland\"\n",
    "similar_players = find_similar_players(target_player, df, X_scaled, top_n=2)\n",
    "print(f\"Top 5 players similar to {target_player}:\\n\")\n",
    "print(similar_players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
